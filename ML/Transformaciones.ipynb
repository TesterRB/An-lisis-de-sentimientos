{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_usuarios(content):\n",
    "    texto = content\n",
    "    indice_arroba = texto.find(\"@\")\n",
    "    while indice_arroba > -1:\n",
    "        indice_espacio = texto.find(\" \", indice_arroba)\n",
    "        if indice_espacio == -1:\n",
    "            texto = texto[:indice_arroba]\n",
    "        else:\n",
    "            texto = texto[:indice_arroba] + texto[indice_espacio:]\n",
    "        indice_arroba = texto.find(\"@\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fin, fout in zip(fins, fouts):\n",
    "    with open(fin, \"rt\") as fin_file:\n",
    "        with open(fout, \"wt\") as fout_file:\n",
    "            for line in fin_file:\n",
    "                #Reemplazar los caracteres unicode, no se dejaron tildes porque causan error\n",
    "                strtmp1 = line.replace('\\\\u00f1', 'ñ')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00e1', 'a')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00e9', 'e')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00ed', 'i')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00f3', 'o')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00fa', 'u')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00bf', '¿')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00a1', '¡')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00d1', 'Ñ')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00c1', 'A')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00c9', 'E')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00cd', 'I')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00d3', 'O')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00da', 'U')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00fc', 'ü')\n",
    "                strtmp1 = strtmp1.replace('\\\\u00b0', '')\n",
    "                #Quitar el inicio y el fin del json para dejar solo los tweets\n",
    "                strtmp1 = strtmp1.replace('{\"tweets\": {\"tweet\": ', '')\n",
    "                strtmp1 = strtmp1.replace(']}}', ']')\n",
    "                #Quitar el diccionario que contiene la polaridad y dejarla solo con su valor de sentimiento\n",
    "                strtmp1 = strtmp1.replace('\"sentiment\": {\"polarity\": {\"value\": ', '\"sentiment\": ')\n",
    "                strtmp1 = strtmp1.replace('\"NONE\"}}', '\"NONE\"')\n",
    "                #Asignamos al sentimiento positivo el valor de 1\n",
    "                strtmp1 = strtmp1.replace('\"P\"}}', '1')\n",
    "                strtmp1 = strtmp1.replace('\"NEU\"}}', '\"NEU\"')\n",
    "                #Asignamos al sentimiento negativo el valor de 0\n",
    "                strtmp1 = strtmp1.replace('\"N\"}}', '0')\n",
    "                #eliminación de puntuaciones\n",
    "                strtmp1 = re.sub('[¡!#$).;¿?&°]', '', strtmp1.lower())\n",
    "                fout_file.write(strtmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntuaciones = string.punctuation + \"¡¿\"\n",
    "stopwords = set(STOP_WORDS)\n",
    "\n",
    "def limpieza_de_datos(oracion):\n",
    "    # Eliminar emojis utilizando expresiones regulares\n",
    "    oracion = re.sub(r'[^\\w\\s,]', '', oracion)\n",
    "    \n",
    "    doc = nlp(oracion)\n",
    "    \n",
    "    tokens_limpios = []\n",
    "    for token in doc:\n",
    "        # Ignorar tokens de longitud uno y caracteres no alfabéticos\n",
    "        if token.is_alpha and len(token.text) > 1:\n",
    "            # Convertir a minúsculas y lematizar sustantivos y adjetivos\n",
    "            if token.lemma_ != \"-PRON-\" and token.pos_ in ['NOUN', 'ADJ']:\n",
    "                temp = token.lemma_.lower().strip()\n",
    "            else:\n",
    "                temp = token.lower_\n",
    "            \n",
    "            # Filtrar stopwords y puntuaciones\n",
    "            if temp not in stopwords and temp not in puntuaciones:\n",
    "                tokens_limpios.append(temp)\n",
    "    \n",
    "    return tokens_limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
